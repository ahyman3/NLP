{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original token: adventurers\n",
      "porter token: adventur\n",
      "lancaster token: adv\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "import numpy as np\n",
    "\n",
    "f = open(\"desert.txt\")\n",
    "text = f.read()\n",
    "f.close()\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "porterTokens = [porter.stem(t) for t in tokens]\n",
    "lancasterTokens = [lancaster.stem(t) for t in tokens]\n",
    "\n",
    "np.random.seed(111)\n",
    "\n",
    "ix = int(np.floor((len(tokens))* np.random.uniform()))\n",
    "\n",
    "print(\"original token: {:s}\\nporter token: {:s}\\nlancaster token: {:s}\".\\\n",
    "      format(tokens[ix], porterTokens[ix], lancasterTokens[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the following, i.e. work with either the regular pattern or the tweet pattern in the tokenizer.  \n",
    "\n",
    "1. Run the regexp tokenizer with the regular pattern on the sentence Mr. Black and Mrs. Brown attended the lecture by Dr. Gray, but Gov. White wasn’t there.\n",
    "\n",
    "a.\tDesign and add a line to the pattern of this tokenizer so that titles like “Mr.” are tokenized as having the dot inside the token.  Test and add some other titles to your list of titles.\n",
    "\n",
    "b.\tDesign and add the pattern of this tokenizer so that words with a single apostrophe, such as “wasn’t” are taken as a single token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Black', 'and', 'Mrs.', 'Brown', 'attended', 'the', 'lecture', 'by', 'Dr.', 'Gray', 'but', 'Gov.', 'White', \"wasn't\", 'there', '.']\n",
      "['I', \"don't\", 'care', 'whether', 'Dr.', 'Patton', 'said', 'I', \"couldn't\", 'play', 'today', '!', \"He'll\", 'understand', 'if', \"it's\", 'his', 'turn', '.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "sent = \"Mr. Black and Mrs. Brown attended the lecture by Dr. Gray, but Gov. White wasn't there.\" \n",
    "\n",
    "pattern = re.compile('''(?x)\n",
    "                        [A-Z][a-z]+\\.\n",
    "                        |[A-Za-z]+'[a-z]+\n",
    "                        |[\\!\\?\\.]\n",
    "                        |[0-9]+\n",
    "                        |\\w+\n",
    "                    ''')\n",
    "\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "\n",
    "print(tokenizer.tokenize(sent))\n",
    "\n",
    "sent2 = \"I don't care whether Dr. Patton said I couldn't play today! He'll understand if it's his turn.\"\n",
    "\n",
    "print(tokenizer.tokenize(sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

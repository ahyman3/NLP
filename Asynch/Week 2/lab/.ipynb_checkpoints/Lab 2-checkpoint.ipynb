{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 191781 words in Emma\n",
      "There are 7944 unique words in Emma\n"
     ]
    }
   ],
   "source": [
    "#Getting file name\n",
    "emma = nltk.corpus.gutenberg.fileids()[0]\n",
    "#Retreiving emma content\n",
    "emma = nltk.corpus.gutenberg.raw(emma)\n",
    "#Converting to lowercase\n",
    "emma = emma.lower()\n",
    "#Tokenizing the emma words\n",
    "emmaWords = nltk.word_tokenize(emma)\n",
    "print(\"there are {:d} words in Emma\".format(len(emmaWords)))\n",
    "print(\"There are {:d} unique words in Emma\".format(len(set(emmaWords))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \t 12016\n",
      ". \t 6351\n",
      "the \t 5201\n",
      "to \t 5181\n",
      "and \t 4877\n",
      "of \t 4284\n",
      "i \t 3177\n",
      "a \t 3124\n",
      "-- \t 3100\n",
      "it \t 2503\n",
      "'' \t 2452\n",
      "her \t 2448\n",
      "was \t 2396\n",
      "; \t 2353\n",
      "she \t 2336\n",
      "not \t 2281\n",
      "in \t 2173\n",
      "be \t 1970\n",
      "you \t 1967\n",
      "he \t 1806\n",
      "that \t 1805\n",
      "`` \t 1735\n",
      "had \t 1623\n",
      "but \t 1441\n",
      "as \t 1436\n",
      "for \t 1346\n",
      "have \t 1320\n",
      "is \t 1241\n",
      "with \t 1215\n",
      "very \t 1202\n"
     ]
    }
   ],
   "source": [
    "#Creating frequency distribution\n",
    "emmaDict = FreqDist(emmaWords)\n",
    "#printing word and count in 30 most common words\n",
    "for word, count in emmaDict.most_common(30):\n",
    "    print(\"{:s} \\t {:d}\".format(word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \t 11454\n",
      ". \t 6928\n",
      "to \t 5239\n",
      "the \t 5201\n",
      "and \t 4896\n",
      "of \t 4291\n",
      "i \t 3178\n",
      "a \t 3129\n",
      "it \t 2528\n",
      "her \t 2469\n",
      "was \t 2398\n",
      "she \t 2340\n",
      "; \t 2199\n",
      "in \t 2188\n",
      "not \t 2140\n",
      "\" \t 2004\n",
      "you \t 1980\n",
      "be \t 1975\n",
      "that \t 1806\n",
      "he \t 1806\n",
      "had \t 1624\n",
      "but \t 1441\n",
      "as \t 1436\n",
      "-- \t 1382\n",
      "for \t 1347\n",
      "have \t 1320\n",
      "is \t 1240\n",
      "with \t 1217\n",
      "very \t 1202\n",
      "mr \t 1153\n"
     ]
    }
   ],
   "source": [
    "#Potentially processed?\n",
    "emmaWords2 = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "#lowercase of words\n",
    "emmaWords2 = [w.lower() for w in emmaWords2]\n",
    "#creating a new frequenct dictionary\n",
    "emmaDict2 = FreqDist(emmaWords2)\n",
    "#New word count\n",
    "for word, count in emmaDict2.most_common(30):\n",
    "    print(\"{:s} \\t {:d}\".format(word, count))\n",
    "#the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Indexing without error\n",
    "emmaDict2.get(\"her\", \"Not found\")\n",
    "print(\"dave\" in emmaDict2)\n",
    "print(\"dave\" not in emmaDict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordFinder(substring, wordlist):\n",
    "    results = []\n",
    "    for word in wordlist:\n",
    "        if substring in word:\n",
    "            results.append(word)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = wordFinder(\"zz\", emmaWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drizzle',\n",
       " 'puzzled',\n",
       " 'puzzles',\n",
       " 'puzzling',\n",
       " 'puzzled',\n",
       " 'puzzle',\n",
       " 'puzzle',\n",
       " 'puzzled']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Alpha\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(\"^[^a-z]+$\")\n",
    "nonAlphaMatch = pattern.match(\"**\")\n",
    "if nonAlphaMatch: print(\"Non-Alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_filter(word):\n",
    "    pattern = re.compile(\"^[^a-z]+$\")\n",
    "    if pattern.match(word):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmaWords2 = [word for word in emmaWords2 if not alpha_filter(word)]\n",
    "emmaDict2 = FreqDist(emmaWords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 5239),\n",
       " ('the', 5201),\n",
       " ('and', 4896),\n",
       " ('of', 4291),\n",
       " ('i', 3178),\n",
       " ('a', 3129),\n",
       " ('it', 2528),\n",
       " ('her', 2469),\n",
       " ('was', 2398),\n",
       " ('she', 2340),\n",
       " ('in', 2188),\n",
       " ('not', 2140),\n",
       " ('you', 1980),\n",
       " ('be', 1975),\n",
       " ('that', 1806),\n",
       " ('he', 1806),\n",
       " ('had', 1624),\n",
       " ('but', 1441),\n",
       " ('as', 1436),\n",
       " ('for', 1347),\n",
       " ('have', 1320),\n",
       " ('is', 1240),\n",
       " ('with', 1217),\n",
       " ('very', 1202),\n",
       " ('mr', 1153),\n",
       " ('his', 1145),\n",
       " ('at', 1031),\n",
       " ('so', 974),\n",
       " ('s', 935),\n",
       " ('emma', 865)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emmaDict2.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "emmaWords2 = [word for word in emmaWords2 if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mr', 1153),\n",
       " ('emma', 865),\n",
       " ('could', 837),\n",
       " ('would', 820),\n",
       " ('mrs', 699),\n",
       " ('miss', 599),\n",
       " ('must', 567),\n",
       " ('harriet', 506),\n",
       " ('much', 486),\n",
       " ('said', 484),\n",
       " ('one', 452),\n",
       " ('weston', 440),\n",
       " ('every', 435),\n",
       " ('well', 401),\n",
       " ('thing', 398),\n",
       " ('knightley', 389),\n",
       " ('elton', 385),\n",
       " ('think', 383),\n",
       " ('little', 359),\n",
       " ('never', 358),\n",
       " ('good', 358),\n",
       " ('know', 337),\n",
       " ('might', 326),\n",
       " ('woodhouse', 313),\n",
       " ('say', 310),\n",
       " ('jane', 301),\n",
       " ('quite', 282),\n",
       " ('time', 279),\n",
       " ('great', 264),\n",
       " ('nothing', 256)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emmaDict2 = FreqDist(emmaWords2)\n",
    "emmaDict2.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating bigrams\n",
    "emmaBigrams = list(nltk.bigrams(emmaWords2))\n",
    "bigramDict = FreqDist(emmaBigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('mr', 'knightley'), 299),\n",
       " (('mrs', 'weston'), 256),\n",
       " (('mr', 'elton'), 229),\n",
       " (('miss', 'woodhouse'), 173),\n",
       " (('mr', 'weston'), 167),\n",
       " (('frank', 'churchill'), 151),\n",
       " (('mrs', 'elton'), 150),\n",
       " (('mr', 'woodhouse'), 135),\n",
       " (('every', 'thing'), 126),\n",
       " (('miss', 'fairfax'), 125),\n",
       " (('miss', 'bates'), 113),\n",
       " (('jane', 'fairfax'), 111),\n",
       " (('every', 'body'), 109),\n",
       " (('young', 'man'), 84),\n",
       " (('said', 'emma'), 65),\n",
       " (('great', 'deal'), 64),\n",
       " (('emma', 'could'), 62),\n",
       " (('mrs', 'goddard'), 59),\n",
       " (('miss', 'smith'), 58),\n",
       " (('john', 'knightley'), 58),\n",
       " (('dare', 'say'), 51),\n",
       " (('mr', 'frank'), 50),\n",
       " (('miss', 'taylor'), 48),\n",
       " (('said', 'mr'), 44),\n",
       " (('mrs', 'churchill'), 42),\n",
       " (('mr', 'mrs'), 39),\n",
       " (('mr', 'perry'), 39),\n",
       " (('mr', 'martin'), 38),\n",
       " (('dear', 'emma'), 33),\n",
       " (('mrs', 'cole'), 32)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramDict.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(emmaWords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('to', 'be'), 0.0031546399278343526),\n",
       " (('of', 'the'), 0.002914783007701493),\n",
       " (('in', 'the'), 0.0023203549882417967),\n",
       " (('it', 'was'), 0.002304712145624436),\n",
       " (('i', 'am'), 0.0020544266637466694),\n",
       " (('she', 'had'), 0.0017311412496545538),\n",
       " (('she', 'was'), 0.00171028412616474),\n",
       " (('had', 'been'), 0.001600784227843217),\n",
       " (('it', 'is'), 0.0015538556999911356),\n",
       " (('i', 'have'), 0.0014652129251594267)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('26th', 'ult.'), 17.549100272146536),\n",
       " (('_a_', '_source_'), 17.549100272146536),\n",
       " (('_amor_', '_patriae_'), 17.549100272146536),\n",
       " (('_and_', '_misery_'), 17.549100272146536),\n",
       " (('_any_', '_thing_'), 17.549100272146536),\n",
       " (('_be_', '_a_'), 17.549100272146536),\n",
       " (('_caro_', '_sposo_'), 17.549100272146536),\n",
       " (('_dissolved_', '_it_.'), 17.549100272146536),\n",
       " (('_great_', '_way_'), 17.549100272146536),\n",
       " (('_most_', '_precious_'), 17.549100272146536),\n",
       " (('_precious_', '_treasures_'), 17.549100272146536),\n",
       " (('_repentance_', '_and_'), 17.549100272146536),\n",
       " (('_rev._', '_philip_'), 17.549100272146536),\n",
       " (('_robin_', '_adair_'), 17.549100272146536),\n",
       " (('_small_', 'half-glass'), 17.549100272146536),\n",
       " (('_with_', '_time_'), 17.549100272146536),\n",
       " (('adequate', 'restoratives'), 17.549100272146536),\n",
       " (('baronne', \"d'almane\"), 17.549100272146536),\n",
       " (('base', 'aspersion'), 17.549100272146536),\n",
       " (('bulky', 'forms'), 17.549100272146536),\n",
       " (('christened', 'catherine'), 17.549100272146536),\n",
       " (('clear-sighted', 'goodwill.'), 17.549100272146536),\n",
       " (('coarser', 'featured'), 17.549100272146536),\n",
       " (('comtesse', \"d'ostalis\"), 17.549100272146536),\n",
       " (('dated', 'sept.'), 17.549100272146536),\n",
       " (('daughter-in-law', 'elect'), 17.549100272146536),\n",
       " (('de', 'genlis'), 17.549100272146536),\n",
       " (('designedly', 'suppress'), 17.549100272146536),\n",
       " (('dexterously', 'throwing'), 17.549100272146536),\n",
       " (('dispiriting', 'cogitation'), 17.549100272146536)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored2 = finder.score_ngrams(bigram_measures.pmi)\n",
    "scored2[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('d', \"'ye\"), 14.964137771425378),\n",
       " (('sore', 'throat'), 14.089668653509236),\n",
       " (('brunswick', 'square'), 13.952165129759301),\n",
       " (('william', 'larkins'), 13.089668653509237),\n",
       " (('baked', 'apples'), 12.964137771425378),\n",
       " (('box', 'hill'), 12.736031698894537),\n",
       " (('sixteen', 'miles'), 12.613640524341246),\n",
       " (('maple', 'grove'), 12.594903961759657),\n",
       " (('hair', 'cut'), 12.063673444976294),\n",
       " (('south', 'end'), 11.96413777142538),\n",
       " (('colonel', 'campbell'), 11.412204071091695),\n",
       " (('protest', 'against'), 11.347466410976883),\n",
       " (('robert', 'martin'), 11.093905646395706),\n",
       " (('five', 'couple'), 10.841741140065652),\n",
       " (('vast', 'deal'), 10.76250391025573),\n",
       " (('ready', 'wit'), 10.652263341201937),\n",
       " (('donwell', 'abbey'), 10.519352928752479),\n",
       " (('musical', 'society'), 10.509084593298656),\n",
       " (('infinitely', 'superior'), 10.23078343081155),\n",
       " (('married', 'women'), 10.05724717581686),\n",
       " (('five', 'minutes'), 10.032683922777048),\n",
       " (('years', 'ago'), 9.957474041144364),\n",
       " (('three', 'months'), 9.941769958396923),\n",
       " (('depend', 'upon'), 9.928095021499848),\n",
       " (('ten', 'minutes'), 9.866983507196462),\n",
       " (('sat', 'down'), 9.795326390293773),\n",
       " (('hurrying', 'away'), 9.603071282631058),\n",
       " (('few', 'moments'), 9.55814541174954),\n",
       " (('few', 'minutes'), 9.4151874579075),\n",
       " (('lovely', 'woman'), 9.400369492973345)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = BigramCollocationFinder.from_words(emmaWords)\n",
    "finder.apply_freq_filter(5)\n",
    "scores = finder.score_ngrams(bigram_measures.pmi)\n",
    "scores[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Lab\n",
    "---\n",
    "As demonstrated in the lab session:\n",
    "\n",
    "Choose a file that you want to work onâ€”either one of the files from the book corpus or one from the Gutenberg corpus.\n",
    "\n",
    "Make a bigram finder and experiment with whether to apply the filters or not. Run the scoring with both the raw frequency and the pmi scorers and compare results.\n",
    "\n",
    "To complete the exercise, choose one of your top 20 frequency lists to report to show to the class. Write an introductory sentence or paragraph telling what text you chose and what bigram filters and scorer you used. Put this and the frequency list in your response. You may check out the frequency lists of other corpora by other students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('samuel', 'enderby'), 14.310865404520303),\n",
       " (('heidelburgh', 'tun'), 13.770297023157601),\n",
       " (('father', 'mapple'), 13.237801942330577),\n",
       " (('huzza', 'porpoise'), 13.066690025937827),\n",
       " (('fiery', 'pit'), 12.922300116602653),\n",
       " (('steering', 'oar'), 12.069857305016509),\n",
       " (('slouched', 'hat'), 11.99268944449405),\n",
       " (('centuries', 'ago'), 11.822764443051735),\n",
       " (('cape', 'horn'), 11.763870753998166),\n",
       " (('moby', 'dick'), 11.583094030283455),\n",
       " (('seven', 'hundred'), 11.518758256161634),\n",
       " (('new', 'york'), 11.363332824414439),\n",
       " (('new', 'zealand'), 11.363332824414439),\n",
       " (('new', 'bedford'), 11.363332824414437),\n",
       " (('book', 'ii'), 10.986263175334615),\n",
       " (('saturday', 'night'), 10.76387075399817),\n",
       " (('drew', 'nigh'), 10.65878870794061),\n",
       " (('english', 'whalers'), 10.451980181822618),\n",
       " (('years', 'ago'), 10.40772694377289),\n",
       " (('brought', 'alongside'), 10.31180252377436)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import *\n",
    "from nltk.collocations import *\n",
    "import re\n",
    "\n",
    "#Filter for only alpha words\n",
    "def alpha_filter(word):\n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if pattern.match(word):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#List of stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#List of moby dick words\n",
    "melville = nltk.corpus.gutenberg.words('melville-moby_dick.txt')\n",
    "melville = [w.lower() for w in melville]\n",
    "\n",
    "#Getting the different measures for bigram analysis\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures\n",
    "#finding bigrams from the corpus\n",
    "finder = BigramCollocationFinder.from_words(melville)\n",
    "#Requiring 5 instances of the bigram \n",
    "finder.apply_freq_filter(5)\n",
    "#Getting rid of non-alphabetical words\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "#Removing stopwords\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "#getting the mutual information scores\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "scored[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('sperm', 'whale'), 0.0006901337709292651),\n",
       " (('white', 'whale'), 0.0004064121095472339),\n",
       " (('moby', 'dick'), 0.0003182283499284945),\n",
       " (('old', 'man'), 0.0003105601969181693),\n",
       " (('captain', 'ahab'), 0.00023387866681491763),\n",
       " (('right', 'whale'), 0.00020320605477361695),\n",
       " (('ye', 'see'), 0.00013419267768069045),\n",
       " (('captain', 'peleg'), 0.00012269044816520268),\n",
       " (('cried', 'ahab'), 0.00012269044816520268),\n",
       " (('one', 'hand'), 0.00010735414214455236),\n",
       " (('let', 'us'), 0.00010352006563938977),\n",
       " (('every', 'one'), 9.201783612390202e-05),\n",
       " (('look', 'ye'), 9.201783612390202e-05),\n",
       " (('cried', 'stubb'), 8.818375961873943e-05),\n",
       " (('never', 'mind'), 8.434968311357684e-05),\n",
       " (('one', 'side'), 8.434968311357684e-05),\n",
       " (('thou', 'art'), 8.051560660841427e-05),\n",
       " (('new', 'bedford'), 6.901337709292652e-05),\n",
       " (('said', 'stubb'), 6.901337709292652e-05),\n",
       " (('sperm', 'whales'), 6.901337709292652e-05)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored2 = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "scored2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alex Hyman\n",
    "\n",
    "Homework #1\n",
    "\n",
    "10/16/2018\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The two texts I have chosen to compare are Moby Dick by Herman Melville and 20,000 Leagues Under the Sea by Jules Verne. On the surface, both of the texts have many similarities, primarily the setting being at sea and a climactic fight with a giant sea animal, but I am most interested in comparing the style between the American Melville and the translated words from the French Verne. Specifically, I am primarily interested in seeing if the translation of the French 20,000 Leagues Under the Sea has the same American-isms or descriptive language that Moby Dick contains, or if the text contains more straightforward story-telling. The Moby Dick corpus was collected from the Gutenberg Project text already loaded into the nltk package, and 20,000 Leagues Under the Sea was collected from the project Gutenberg Project as a text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "#Open 20,000 Leagues under the sea file\n",
    "f = open('leagues.txt')\n",
    "#Get the text from the file\n",
    "leagues = f.read()\n",
    "#Get the text of moby dick\n",
    "mobydick = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Text\n",
    "\n",
    "The key to processing the text in this analysis is to tokenize the various test. 20,000 Leagues has already been read into the python environment as a string from the text file, and Moby Dick was loaded into the python environment through the nltk package. To make the texts usable, the contents need to be separated into tokens. The nltk.word_tokenize function will be used to separate the puctuation and the various words.\n",
    "\n",
    "One issue I had found during this step was that there were a lot of words that did not seem appropriate in the 20,000 leagues tokens. It turned out that the 20,000 Leagues Under the Sea file downloaded from the Project Gutenberg website contained a long list of credits and text unrelated to the actual novel, referring to how the text was a part of the Gutenberg Project and in the public domain. Because of this, weird bigrams began showing up that did not make sense in the context. Therefore, in the .txt file I had download, I deleted everything above the note \"\\*\\*\\**Book begins here***\\*\" and everything after the note \"\\*\\*\\**Book ends here***\\*\". 20,000 Leagues Under the Sea was found to have 123677 tokens and Moby Dick was fount to have 254989 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby Dick # of tokens: 254989\n",
      "20,000 Leagues Under the Sea # of tokens: 123677\n"
     ]
    }
   ],
   "source": [
    "#Tokenize 20,000 Leagues\n",
    "leaguesTokens = nltk.word_tokenize(leagues)\n",
    "#Tokenize moby dick\n",
    "mobydickTokens = nltk.word_tokenize(mobydick)\n",
    "#Make all tokens lowercase in both texts\n",
    "leaguesTokens = [w.lower() for w in leaguesTokens]\n",
    "mobydickTokens = [w.lower() for w in mobydickTokens]\n",
    "print(\"Moby Dick # of tokens: {:d}\".format(len(mobydickTokens)))\n",
    "print(\"20,000 Leagues Under the Sea # of tokens: {:d}\".format(len(leaguesTokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphabetical and Stopword Filter\n",
    "\n",
    "While an alphabetical and stopword filter will not be used to remove words before the bigram analysis, a stopword and non-alphabetical filter will be used to remove words from the word frequency analysis; and after the bigrams are processed, this filter will remove bigrams that contain punctuation or stopwords. Additionally, french stopwords were included in this filter because of the presence of some french articles in 20,000 Leagues under the sea (la, le, les, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns true for any stopwords and any non-alphabetic tokens\n",
    "def alphaFilter(word):\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    stopwords = stopwords + nltk.corpus.stopwords.words(\"french\")\n",
    "    if word in stopwords:\n",
    "        return True\n",
    "    else:\n",
    "        pattern = re.compile('[^a-z]')\n",
    "        m = pattern.match(word)\n",
    "        if m is not None:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moby Dick Corpus Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency \n",
    "\n",
    "First, a word frequency analysis was conducted on the Moby Dick tokens. The alphabetical and stopword filter was applied to the tokens in the Moby Dick tokens list, but was applied only within the FreqDist function to ensure the stopwords and punctuation remained for the bigram analysis. With these tokens removed from the Moby Dick token list, a Frequency Dictionary was created.\n",
    "\n",
    "Next, the most_common method was used on the dictionary to find the 50 most used words not removed from the filter. Then, with each of the words and counts in the most common 50 words, the word was printed, along with the word count number divided by the length of the entire Moby Dick token list. This normalized the word counts to be between 0 and 1, with the frequency shown being the fraction of how many times the token appears, compared to all other tokens.\n",
    "\n",
    "The words that appeared on the word frequency list were typically either related to the sea, masculine, or a fairly general noun, verb, or adjective. \"Whale\" was the most frequently occurring word, followed by \"one\" and \"like\". There also appears to be a prevalence of stereotypical old english words in the word frequency list, including \"upon\", \"ye\", \"yet\", and \"thou\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby Dick Normalized Word Frequency - Stopwords Removed\n",
      "\n",
      "Word: whale        \tFrequency: 0.00426\n",
      "Word: one        \tFrequency: 0.00358\n",
      "Word: like        \tFrequency: 0.00227\n",
      "Word: upon        \tFrequency: 0.00222\n",
      "Word: ahab        \tFrequency: 0.00199\n",
      "Word: man        \tFrequency: 0.00192\n",
      "Word: ship        \tFrequency: 0.00182\n",
      "Word: old        \tFrequency: 0.00174\n",
      "Word: ye        \tFrequency: 0.00172\n",
      "Word: would        \tFrequency: 0.00171\n",
      "Word: sea        \tFrequency: 0.00151\n",
      "Word: though        \tFrequency: 0.00150\n",
      "Word: yet        \tFrequency: 0.00135\n",
      "Word: time        \tFrequency: 0.00128\n",
      "Word: captain        \tFrequency: 0.00127\n",
      "Word: long        \tFrequency: 0.00125\n",
      "Word: still        \tFrequency: 0.00122\n",
      "Word: said        \tFrequency: 0.00119\n",
      "Word: great        \tFrequency: 0.00119\n",
      "Word: two        \tFrequency: 0.00113\n",
      "Word: boat        \tFrequency: 0.00113\n",
      "Word: must        \tFrequency: 0.00111\n",
      "Word: seemed        \tFrequency: 0.00111\n",
      "Word: head        \tFrequency: 0.00109\n",
      "Word: last        \tFrequency: 0.00108\n",
      "Word: see        \tFrequency: 0.00105\n",
      "Word: thou        \tFrequency: 0.00105\n",
      "Word: whales        \tFrequency: 0.00105\n",
      "Word: way        \tFrequency: 0.00104\n",
      "Word: stubb        \tFrequency: 0.00100\n",
      "Word: n't        \tFrequency: 0.00099\n",
      "Word: queequeg        \tFrequency: 0.00099\n",
      "Word: little        \tFrequency: 0.00098\n",
      "Word: white        \tFrequency: 0.00097\n",
      "Word: round        \tFrequency: 0.00096\n",
      "Word: say        \tFrequency: 0.00095\n",
      "Word: sperm        \tFrequency: 0.00094\n",
      "Word: three        \tFrequency: 0.00094\n",
      "Word: men        \tFrequency: 0.00093\n",
      "Word: may        \tFrequency: 0.00093\n",
      "Word: first        \tFrequency: 0.00092\n",
      "Word: every        \tFrequency: 0.00091\n",
      "Word: us        \tFrequency: 0.00089\n",
      "Word: much        \tFrequency: 0.00087\n",
      "Word: could        \tFrequency: 0.00087\n",
      "Word: well        \tFrequency: 0.00086\n",
      "Word: never        \tFrequency: 0.00081\n",
      "Word: hand        \tFrequency: 0.00080\n",
      "Word: good        \tFrequency: 0.00077\n",
      "Word: almost        \tFrequency: 0.00076\n"
     ]
    }
   ],
   "source": [
    "#Creating a frequency dictionary with the applied filter\n",
    "mobyDict = nltk.FreqDist([w for w in mobydickTokens if not alphaFilter(w)])\n",
    "print(\"Moby Dick Normalized Word Frequency - Stopwords Removed\\n\")\n",
    "#For each word and count for the 50 most common words in the dictionary...\n",
    "for w, c in mobyDict.most_common(50):\n",
    "    #Print the word and the count divided by the number of tokens in the non-filtered\n",
    "    #tokenized list\n",
    "    print(\"Word: {:s}        \\tFrequency: {:.5f}\".format(w, c / len(mobydickTokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Frequency\n",
    "\n",
    "The Moby Dick corpus then had its bigrams analyzed for both frequency and PMI. First, the bigram association measures were saved in a variable called bigram_measures and a finder was created to find all bigrams in the list of Moby Dick tokens. The non-alphabetical and puctiation filter was applied to the finder, and then the bigram frequency was scored. Finally, the bigram along with the frequency of the top 50 bigrams were printed out.\n",
    "\n",
    "The contents of the bigrams include have a general theme of being related to the ocean, and specifically whales. The top four bigrams were (\"sperm\", \"whale\"), (\"white\", \"whale\"), and (\"moby\", \"dick\"). It was also noticable there were a few instances where people were crying out ([\"cried\", \"ahab\"], [\"cried\", \"stubb\"], [\"cried\", \"starbuck\"]). This suggests that maybe there were some struggle on the ship. This is further supported by the bigram (\"poor\", \"queequeg\"), which is the name of a character in the novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moby Dick Bigrams - Raw Frequency - Stopword Filtering Applied \n",
      "\n",
      "Bigram: ('sperm', 'whale')  Frequency: 0.00068\n",
      "Bigram: ('white', 'whale')  Frequency: 0.00042\n",
      "Bigram: ('moby', 'dick')  Frequency: 0.00032\n",
      "Bigram: ('old', 'man')  Frequency: 0.00029\n",
      "Bigram: ('captain', 'ahab')  Frequency: 0.00024\n",
      "Bigram: ('right', 'whale')  Frequency: 0.00020\n",
      "Bigram: ('captain', 'peleg')  Frequency: 0.00013\n",
      "Bigram: ('cried', 'ahab')  Frequency: 0.00013\n",
      "Bigram: ('mr.', 'starbuck')  Frequency: 0.00011\n",
      "Bigram: ('wo', \"n't\")  Frequency: 0.00011\n",
      "Bigram: ('one', 'hand')  Frequency: 0.00011\n",
      "Bigram: ('let', 'us')  Frequency: 0.00011\n",
      "Bigram: ('ca', \"n't\")  Frequency: 0.00010\n",
      "Bigram: ('every', 'one')  Frequency: 0.00009\n",
      "Bigram: ('cried', 'stubb')  Frequency: 0.00009\n",
      "Bigram: ('look', 'ye')  Frequency: 0.00009\n",
      "Bigram: ('never', 'mind')  Frequency: 0.00009\n",
      "Bigram: ('one', 'side')  Frequency: 0.00009\n",
      "Bigram: ('thou', 'art')  Frequency: 0.00008\n",
      "Bigram: ('new', 'bedford')  Frequency: 0.00007\n",
      "Bigram: ('said', 'stubb')  Frequency: 0.00007\n",
      "Bigram: ('sperm', 'whales')  Frequency: 0.00007\n",
      "Bigram: ('years', 'ago')  Frequency: 0.00007\n",
      "Bigram: ('cried', 'starbuck')  Frequency: 0.00007\n",
      "Bigram: (\"n't\", 'know')  Frequency: 0.00007\n",
      "Bigram: ('cape', 'horn')  Frequency: 0.00006\n",
      "Bigram: ('greenland', 'whale')  Frequency: 0.00006\n",
      "Bigram: ('lower', 'jaw')  Frequency: 0.00006\n",
      "Bigram: (\"n't\", 'ye')  Frequency: 0.00006\n",
      "Bigram: ('old', 'ahab')  Frequency: 0.00006\n",
      "Bigram: ('something', 'like')  Frequency: 0.00006\n",
      "Bigram: ('whale', 'fishery')  Frequency: 0.00006\n",
      "Bigram: ('young', 'man')  Frequency: 0.00006\n",
      "Bigram: ('ivory', 'leg')  Frequency: 0.00006\n",
      "Bigram: ('thus', 'far')  Frequency: 0.00006\n",
      "Bigram: ('well', 'known')  Frequency: 0.00006\n",
      "Bigram: ('whaling', 'voyage')  Frequency: 0.00006\n",
      "Bigram: ('would', 'seem')  Frequency: 0.00006\n",
      "Bigram: ('captain', 'bildad')  Frequency: 0.00005\n",
      "Bigram: ('chief', 'mate')  Frequency: 0.00005\n",
      "Bigram: ('ere', 'long')  Frequency: 0.00005\n",
      "Bigram: ('ye', 'see')  Frequency: 0.00005\n",
      "Bigram: ('dost', 'thou')  Frequency: 0.00005\n",
      "Bigram: ('ever', 'since')  Frequency: 0.00005\n",
      "Bigram: ('would', 'fain')  Frequency: 0.00005\n",
      "Bigram: ('forty', 'years')  Frequency: 0.00005\n",
      "Bigram: ('much', 'like')  Frequency: 0.00005\n",
      "Bigram: ('one', 'hundred')  Frequency: 0.00005\n",
      "Bigram: ('poor', 'queequeg')  Frequency: 0.00005\n",
      "Bigram: ('three', 'boats')  Frequency: 0.00005\n"
     ]
    }
   ],
   "source": [
    "#variable to store all the bigram measures\n",
    "bigram_measures = nltk.BigramAssocMeasures()\n",
    "\n",
    "#Finds bigrams from \n",
    "finder = nltk.BigramCollocationFinder.from_words(mobydickTokens)\n",
    "finder.apply_word_filter(alphaFilter)\n",
    "mobyFreq = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "print(\"\\nMoby Dick Bigrams - Raw Frequency - Stopword Filtering Applied \\n\")\n",
    "for b, f in mobyFreq[0:50]:\n",
    "    print(\"Bigram: {}  Frequency: {:.5f}\".format(b, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram PMI\n",
    "\n",
    "The bigrams in the Moby Dick corpus were also evaluated on the metric of PMI. PMI takes the log base 2 of how much more likely the bigram is to occur than an occurance by random chance of those two tokens occurring together. A minimum occurance filter of 5 was also applied to the finder make sure that the bigram occurs at least five times in order to be considered. This would be in addition to the stopwords and non-alphavetic filter applied in the frequency analysis. \n",
    "\n",
    "The bigrams that appear in in order if PMI scoring are much more likely to be proper nouns. This is somewhat intuitive as the words used in a name or place are used less frequently than words in normal phrases or bigrams. It is also interesting that a lot of the bigrams from the Moby Dick corpus are related to time or number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moby Dick Bigrams - PMI - Stopword and Min. Frequency Filtering Applied\n",
      "\n",
      "Bigram: ('samuel', 'enderby')  PMI: 14.27825\n",
      "Bigram: ('mrs.', 'hussey')  PMI: 13.87261\n",
      "Bigram: ('heidelburgh', 'tun')  PMI: 13.73768\n",
      "Bigram: ('st.', 'george')  PMI: 13.34864\n",
      "Bigram: ('father', 'mapple')  PMI: 13.25964\n",
      "Bigram: ('huzza', 'porpoise')  PMI: 13.03408\n",
      "Bigram: ('fiery', 'pit')  PMI: 12.88969\n",
      "Bigram: ('steering', 'oar')  PMI: 12.37511\n",
      "Bigram: ('cape', 'horn')  PMI: 11.93217\n",
      "Bigram: ('seven', 'hundred')  PMI: 11.90118\n",
      "Bigram: ('centuries', 'ago')  PMI: 11.79015\n",
      "Bigram: ('moby', 'dick')  PMI: 11.58482\n",
      "Bigram: ('new', 'york')  PMI: 11.55068\n",
      "Bigram: ('new', 'zealand')  PMI: 11.55068\n",
      "Bigram: ('new', 'bedford')  PMI: 11.55068\n",
      "Bigram: ('book', 'ii')  PMI: 11.12719\n",
      "Bigram: ('saturday', 'night')  PMI: 10.90479\n",
      "Bigram: ('drew', 'nigh')  PMI: 10.65934\n",
      "Bigram: ('chief', 'mate')  PMI: 10.64331\n",
      "Bigram: ('years', 'ago')  PMI: 10.45228\n",
      "Bigram: ('english', 'whalers')  PMI: 10.41937\n",
      "Bigram: ('forty', 'years')  PMI: 10.39339\n",
      "Bigram: ('brought', 'alongside')  PMI: 10.27919\n",
      "Bigram: ('lower', 'jaw')  PMI: 10.20519\n",
      "Bigram: ('four', 'oceans')  PMI: 10.19454\n",
      "Bigram: ('thousand', 'miles')  PMI: 10.12357\n",
      "Bigram: ('drawing', 'nigh')  PMI: 10.07438\n",
      "Bigram: ('new', 'england')  PMI: 10.03611\n",
      "Bigram: ('pagan', 'harpooneers')  PMI: 10.01522\n",
      "Bigram: ('ca', \"n't\")  PMI: 9.98280\n",
      "Bigram: ('wo', \"n't\")  PMI: 9.98280\n",
      "Bigram: ('closed', 'eyes')  PMI: 9.93771\n",
      "Bigram: ('full', 'grown')  PMI: 9.81797\n",
      "Bigram: ('good', 'deal')  PMI: 9.75306\n",
      "Bigram: ('pequod', 'meets')  PMI: 9.74576\n",
      "Bigram: ('ivory', 'leg')  PMI: 9.73511\n",
      "Bigram: ('drew', 'near')  PMI: 9.69329\n",
      "Bigram: ('thou', 'knowest')  PMI: 9.63095\n",
      "Bigram: ('good', 'luck')  PMI: 9.44494\n",
      "Bigram: ('fair', 'wind')  PMI: 9.39212\n",
      "Bigram: ('poor', 'devils')  PMI: 9.38719\n",
      "Bigram: ('mr.', 'starbuck')  PMI: 9.35275\n",
      "Bigram: ('little', 'king-post')  PMI: 9.26311\n",
      "Bigram: ('dost', 'thou')  PMI: 9.20211\n",
      "Bigram: ('whaling', 'vessels')  PMI: 9.18859\n",
      "Bigram: ('old', 'mogul')  PMI: 9.16891\n",
      "Bigram: ('twenty', 'feet')  PMI: 9.13489\n",
      "Bigram: ('thirty', 'years')  PMI: 9.13035\n",
      "Bigram: ('drawing', 'near')  PMI: 9.10833\n",
      "Bigram: ('murmured', 'starbuck')  PMI: 9.08971\n"
     ]
    }
   ],
   "source": [
    "#Applying a minimum bigram frequency filter\n",
    "finder.apply_freq_filter(min_freq=5)\n",
    "mobyPMI = finder.score_ngrams(bigram_measures.pmi)\n",
    "print(\"\\nMoby Dick Bigrams - PMI - Stopword and Min. Frequency Filtering Applied\\n\")\n",
    "for b, pmi in mobyPMI[0:50]:\n",
    "    print(\"Bigram: {}  PMI: {:.5f}\".format(b, pmi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams\n",
    "\n",
    "An analysis of the trigrams in Moby Dick was also conducted. Similar to the bigrams, the potential trigrams were narrowed down to have a minimum frequency of 3, and to not contain any stopwords or puntuation. The minimum frequency was applied to the trigrams before the word filter because the minimum frequency narrows dow the potential trigrams significantly and allows the trigrams to be processed quicker. There were only 22 different trigrams that met these standards\n",
    "\n",
    "The trigrams that appeared most frequently generally already had a frequently occurring bigram. In fact, there were three different trigrams that contained the most frequently occurring bigram, sperm whale. Aside from the trigrams that contained \"sperm whale\", the only other repeated pattern in the trigrams is the decription if a time period \"X\" years ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('great', 'sperm', 'whale'), 4.313911580499551e-05),\n",
       " (('every', 'one', 'knows'), 3.529564020408723e-05),\n",
       " (('sperm', 'whale', 'fishery'), 1.9608689002270686e-05),\n",
       " (('wo', \"n't\", 'ye'), 1.9608689002270686e-05),\n",
       " (('god', 'bless', 'ye'), 1.568695120181655e-05),\n",
       " (('old', 'manx', 'sailor'), 1.568695120181655e-05),\n",
       " (('round', 'cape', 'horn'), 1.568695120181655e-05),\n",
       " (('thou', 'clear', 'spirit'), 1.568695120181655e-05),\n",
       " (('ca', \"n't\", 'sell'), 1.1765213401362411e-05),\n",
       " (('fifty', 'years', 'ago'), 1.1765213401362411e-05),\n",
       " (('first', 'congregational', 'church'), 1.1765213401362411e-05),\n",
       " (('first', 'night', 'watch'), 1.1765213401362411e-05),\n",
       " (('forty', 'years', 'ago'), 1.1765213401362411e-05),\n",
       " (('great', 'heidelburgh', 'tun'), 1.1765213401362411e-05),\n",
       " (('great', 'south', 'sea'), 1.1765213401362411e-05),\n",
       " (('large', 'sperm', 'whale'), 1.1765213401362411e-05),\n",
       " (('let', 'us', 'fly'), 1.1765213401362411e-05),\n",
       " (('queequeg', 'dies', 'game'), 1.1765213401362411e-05),\n",
       " (('shall', 'ere', 'long'), 1.1765213401362411e-05),\n",
       " (('stop', 'dat', 'dam'), 1.1765213401362411e-05),\n",
       " (('thou', 'grinning', 'whale'), 1.1765213401362411e-05),\n",
       " (('three', 'centuries', 'ago'), 1.1765213401362411e-05)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Moby Dick Trigram Finder\n",
    "triFinder = nltk.TrigramCollocationFinder.from_words(mobydickTokens)\n",
    "#At Least 5 times\n",
    "triFinder.apply_freq_filter(min_freq=3)\n",
    "#No Punctuation\n",
    "triFinder.apply_word_filter(alphaFilter)\n",
    "#Scoring Methods For trigrams\n",
    "triScore = nltk.TrigramAssocMeasures()\n",
    "#Scored trigrams\n",
    "trigrams = triFinder.score_ngrams(triScore.raw_freq)\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20,000 Leagues Under the Sea Corpus Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency\n",
    "\n",
    "The most frequent words and bigrams in 20,000 Leagues Under the Sea were found using the same techniques and methods used to find the most frequent words and bigrams in Moby Dick.\n",
    "\n",
    "The most common words that remained after the removal of stopwords and non-alphabetic tokens were largely related to the ocean or the characters. Once again the sea-faring vessel (nautilis) appeared as one of the most frequently occurring tokens along with the captain of the ship, nemo. The frequently occurring words appear to be more gender neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20,000 Leagues Under the Sea Normalized Word Frequency - Stopwords Removed\n",
      "\n",
      "Word: captain        \tFrequency: 0.00514\n",
      "Word: nautilus        \tFrequency: 0.00420\n",
      "Word: nemo        \tFrequency: 0.00301\n",
      "Word: one        \tFrequency: 0.00289\n",
      "Word: said        \tFrequency: 0.00269\n",
      "Word: ned        \tFrequency: 0.00260\n",
      "Word: could        \tFrequency: 0.00250\n",
      "Word: sea        \tFrequency: 0.00244\n",
      "Word: us        \tFrequency: 0.00241\n",
      "Word: would        \tFrequency: 0.00232\n",
      "Word: conseil        \tFrequency: 0.00227\n",
      "Word: land        \tFrequency: 0.00208\n",
      "Word: water        \tFrequency: 0.00172\n",
      "Word: two        \tFrequency: 0.00171\n",
      "Word: like        \tFrequency: 0.00167\n",
      "Word: sir        \tFrequency: 0.00158\n",
      "Word: long        \tFrequency: 0.00136\n",
      "Word: see        \tFrequency: 0.00122\n",
      "Word: feet        \tFrequency: 0.00117\n",
      "Word: surface        \tFrequency: 0.00116\n",
      "Word: must        \tFrequency: 0.00116\n",
      "Word: canadian        \tFrequency: 0.00115\n",
      "Word: time        \tFrequency: 0.00114\n",
      "Word: day        \tFrequency: 0.00112\n",
      "Word: without        \tFrequency: 0.00112\n",
      "Word: well        \tFrequency: 0.00112\n",
      "Word: replied        \tFrequency: 0.00110\n",
      "Word: made        \tFrequency: 0.00108\n",
      "Word: ocean        \tFrequency: 0.00103\n",
      "Word: saw        \tFrequency: 0.00099\n",
      "Word: seemed        \tFrequency: 0.00096\n",
      "Word: great        \tFrequency: 0.00096\n",
      "Word: man        \tFrequency: 0.00096\n",
      "Word: air        \tFrequency: 0.00094\n",
      "Word: went        \tFrequency: 0.00092\n",
      "Word: still        \tFrequency: 0.00090\n",
      "Word: upon        \tFrequency: 0.00089\n",
      "Word: light        \tFrequency: 0.00089\n",
      "Word: miles        \tFrequency: 0.00086\n",
      "Word: last        \tFrequency: 0.00084\n",
      "Word: yards        \tFrequency: 0.00083\n",
      "Word: vessel        \tFrequency: 0.00083\n",
      "Word: waves        \tFrequency: 0.00081\n",
      "Word: waters        \tFrequency: 0.00080\n",
      "Word: know        \tFrequency: 0.00078\n",
      "Word: first        \tFrequency: 0.00076\n",
      "Word: nothing        \tFrequency: 0.00076\n",
      "Word: large        \tFrequency: 0.00076\n",
      "Word: board        \tFrequency: 0.00076\n",
      "Word: boat        \tFrequency: 0.00074\n"
     ]
    }
   ],
   "source": [
    "#Creating a frequency dictionary with the applied filter\n",
    "leaguesDict = nltk.FreqDist([w for w in leaguesTokens if not alphaFilter(w)])\n",
    "print(\"20,000 Leagues Under the Sea Normalized Word Frequency - Stopwords Removed\\n\")\n",
    "#For each word and count for the 50 most common words in the dictionary...\n",
    "for w, c in leaguesDict.most_common(50):\n",
    "    #Print the word and the count divided by the number of tokens in the non-filtered\n",
    "    #tokenized list\n",
    "    print(\"Word: {:s}        \\tFrequency: {:.5f}\".format(w, c / len(leaguesTokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Frequency\n",
    "\n",
    "The frequency analysis of the bigrams in 20,000 Leagues Under the Sea underwent the same processing that the Moby Dick bigrams went through. The frequently occurring bigrams in 20,000 Leagues Under the Sea were primarily either proper nouns, or common phrases. The only maritime related phrase in the frequent bigram list is (\"submarine\", \"boat\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20,000 Leagues Under the Sea Bigrams - Raw Frequency - Stopword Filtering Applied \n",
      "\n",
      "Bigram: ('captain', 'nemo')  Frequency: 0.00300\n",
      "Bigram: ('ned', 'land')  Frequency: 0.00156\n",
      "Bigram: ('m.', 'aronnax')  Frequency: 0.00043\n",
      "Bigram: ('said', 'conseil')  Frequency: 0.00042\n",
      "Bigram: ('abraham', 'lincoln')  Frequency: 0.00035\n",
      "Bigram: ('let', 'us')  Frequency: 0.00027\n",
      "Bigram: ('next', 'day')  Frequency: 0.00024\n",
      "Bigram: ('said', 'ned')  Frequency: 0.00024\n",
      "Bigram: ('red', 'sea')  Frequency: 0.00020\n",
      "Bigram: ('friend', 'ned')  Frequency: 0.00017\n",
      "Bigram: ('said', 'captain')  Frequency: 0.00016\n",
      "Bigram: ('could', 'see')  Frequency: 0.00015\n",
      "Bigram: ('electric', 'light')  Frequency: 0.00015\n",
      "Bigram: ('feet', 'long')  Frequency: 0.00014\n",
      "Bigram: ('replied', 'conseil')  Frequency: 0.00014\n",
      "Bigram: ('master', 'land')  Frequency: 0.00012\n",
      "Bigram: ('one', 'day')  Frequency: 0.00012\n",
      "Bigram: ('south', 'pole')  Frequency: 0.00012\n",
      "Bigram: ('replied', 'ned')  Frequency: 0.00011\n",
      "Bigram: ('two', 'hours')  Frequency: 0.00011\n",
      "Bigram: ('replied', 'captain')  Frequency: 0.00011\n",
      "Bigram: ('several', 'times')  Frequency: 0.00011\n",
      "Bigram: ('two', 'miles')  Frequency: 0.00011\n",
      "Bigram: ('commander', 'farragut')  Frequency: 0.00010\n",
      "Bigram: ('gulf', 'stream')  Frequency: 0.00010\n",
      "Bigram: ('open', 'sea')  Frequency: 0.00010\n",
      "Bigram: ('central', 'staircase')  Frequency: 0.00009\n",
      "Bigram: ('dumont', \"d'urville\")  Frequency: 0.00009\n",
      "Bigram: ('indian', 'ocean')  Frequency: 0.00009\n",
      "Bigram: ('thirty', 'feet')  Frequency: 0.00009\n",
      "Bigram: ('two', 'yards')  Frequency: 0.00009\n",
      "Bigram: ('yards', 'long')  Frequency: 0.00009\n",
      "Bigram: ('asked', 'conseil')  Frequency: 0.00008\n",
      "Bigram: ('carried', 'away')  Frequency: 0.00008\n",
      "Bigram: ('eleven', \"o'clock\")  Frequency: 0.00008\n",
      "Bigram: ('hundred', 'feet')  Frequency: 0.00008\n",
      "Bigram: ('ten', 'yards')  Frequency: 0.00008\n",
      "Bigram: ('twenty', 'miles')  Frequency: 0.00008\n",
      "Bigram: ('fifty', 'feet')  Frequency: 0.00007\n",
      "Bigram: ('heart', 'beat')  Frequency: 0.00007\n",
      "Bigram: ('new', 'york')  Frequency: 0.00007\n",
      "Bigram: ('six', 'months')  Frequency: 0.00007\n",
      "Bigram: ('submarine', 'boat')  Frequency: 0.00007\n",
      "Bigram: ('two', 'thousand')  Frequency: 0.00007\n",
      "Bigram: ('upper', 'part')  Frequency: 0.00007\n",
      "Bigram: ('cape', 'horn')  Frequency: 0.00006\n",
      "Bigram: ('captain', \"nemo's\")  Frequency: 0.00006\n",
      "Bigram: ('door', 'opened')  Frequency: 0.00006\n",
      "Bigram: ('first', 'time')  Frequency: 0.00006\n",
      "Bigram: ('five', 'hundred')  Frequency: 0.00006\n"
     ]
    }
   ],
   "source": [
    "#Finds bigrams from \n",
    "finder = nltk.BigramCollocationFinder.from_words(leaguesTokens)\n",
    "finder.apply_word_filter(alphaFilter)\n",
    "leaguesFreq = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "print(\"\\n20,000 Leagues Under the Sea Bigrams - Raw Frequency - Stopword Filtering Applied \\n\")\n",
    "for b, f in leaguesFreq[0:50]:\n",
    "    print(\"Bigram: {}  Frequency: {:.5f}\".format(b, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram PMI\n",
    "\n",
    "When looking at the top PMI scored bigrams, many of the bigrams are either geographic location or descriptions or some sort of general phrase. There are not any maritime related bigrams, aside from some famous maritime landmarks; and there are very few names of people in the list. If there were to be some sort of theme in the bigrams with the highest PMI score, it would be famous landmarks, and natural/science related phrases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20,000 Leagues Under the Sea Bigrams - PMI - Stopword and Min. Frequency Filtering Applied \n",
      "\n",
      "Bigram: ('carbonic', 'acid')  PMI: 14.33126\n",
      "Bigram: ('united', 'states')  PMI: 13.33126\n",
      "Bigram: ('dumont', \"d'urville\")  PMI: 13.21578\n",
      "Bigram: ('inclined', 'planes')  PMI: 12.63082\n",
      "Bigram: ('central', 'staircase')  PMI: 12.56829\n",
      "Bigram: ('worthy', 'fellow')  PMI: 12.18286\n",
      "Bigram: ('vigo', 'bay')  PMI: 11.93322\n",
      "Bigram: ('favourable', 'opportunity')  PMI: 11.77871\n",
      "Bigram: ('cape', 'horn')  PMI: 11.53684\n",
      "Bigram: ('torres', 'straits')  PMI: 11.53540\n",
      "Bigram: ('gulf', 'stream')  PMI: 11.44319\n",
      "Bigram: ('luminous', 'ceiling')  PMI: 11.43817\n",
      "Bigram: ('abraham', 'lincoln')  PMI: 11.42362\n",
      "Bigram: ('solar', 'rays')  PMI: 11.40842\n",
      "Bigram: ('ruhmkorff', 'apparatus')  PMI: 11.37190\n",
      "Bigram: ('thousand', 'dollars')  PMI: 11.36778\n",
      "Bigram: ('coral', 'cemetery')  PMI: 11.18286\n",
      "Bigram: ('new', 'york')  PMI: 11.03357\n",
      "Bigram: ('hissing', 'noise')  PMI: 11.00933\n",
      "Bigram: ('forty-eight', 'hours')  PMI: 10.87182\n",
      "Bigram: ('commander', 'farragut')  PMI: 10.79382\n",
      "Bigram: ('northern', 'regions')  PMI: 10.66829\n",
      "Bigram: ('m.', 'aronnax')  PMI: 10.65687\n",
      "Bigram: ('natural', 'history')  PMI: 10.64320\n",
      "Bigram: ('heart', 'beat')  PMI: 10.63493\n",
      "Bigram: ('set', 'foot')  PMI: 10.52390\n",
      "Bigram: ('twenty-four', 'hours')  PMI: 10.50925\n",
      "Bigram: ('eleven', \"o'clock\")  PMI: 10.13748\n",
      "Bigram: ('south', 'pole')  PMI: 10.10886\n",
      "Bigram: ('carried', 'away')  PMI: 10.06322\n",
      "Bigram: ('take', 'possession')  PMI: 9.87182\n",
      "Bigram: ('minutes', 'later')  PMI: 9.75837\n",
      "Bigram: ('second', 'lieutenant')  PMI: 9.68740\n",
      "Bigram: ('arms', 'crossed')  PMI: 9.68740\n",
      "Bigram: ('iron', 'plates')  PMI: 9.62466\n",
      "Bigram: ('must', 'necessarily')  PMI: 9.55365\n",
      "Bigram: ('without', 'noticing')  PMI: 9.53424\n",
      "Bigram: ('six', 'months')  PMI: 9.42436\n",
      "Bigram: ('liquid', 'mass')  PMI: 9.33376\n",
      "Bigram: ('next', 'day')  PMI: 9.31185\n",
      "Bigram: ('several', 'times')  PMI: 9.08333\n",
      "Bigram: ('certain', 'number')  PMI: 9.05699\n",
      "Bigram: ('good', 'hope')  PMI: 9.03532\n",
      "Bigram: ('north', 'pacific')  PMI: 8.98430\n",
      "Bigram: ('upper', 'part')  PMI: 8.93894\n",
      "Bigram: ('american', 'coast')  PMI: 8.93894\n",
      "Bigram: ('sixty', 'feet')  PMI: 8.88831\n",
      "Bigram: ('boiling', 'water')  PMI: 8.69608\n",
      "Bigram: ('greater', 'part')  PMI: 8.63777\n",
      "Bigram: ('thirty', 'feet')  PMI: 8.61078\n"
     ]
    }
   ],
   "source": [
    "#Applying a minimum bigram frequency filter\n",
    "finder.apply_freq_filter(min_freq=5)\n",
    "leaguesPMI = finder.score_ngrams(bigram_measures.pmi)\n",
    "print(\"\\n20,000 Leagues Under the Sea Bigrams - PMI - Stopword and Min. Frequency Filtering Applied \\n\")\n",
    "for b, pmi in leaguesPMI[0:50]:\n",
    "    print(\"Bigram: {}  PMI: {:.5f}\".format(b, pmi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams\n",
    "\n",
    "The trigrams in 20,000 Leagues Under the Sea tokens were also processed to find any frequently occurring trigrams. These trigrams were filtered to ensure that they occurred a minimum of three time, and did not include any non-alphabetic tokens or stopwords. There were 35 different trigrams that met these requirements.\n",
    "\n",
    "The most prominent tokens within the trigrams are \"captain\" and \"nemo\". More than half of the frequently occurring trigrams contained the name Captain Nemo. There were also a prominent amount of action verbs connected with a name, particularly verbs related to dialogue. It is also noteworthy that four different trigrams occur frequently enough within the text that they appear more frequently than some of the most frequently occurring bigrams in 20,000 Leagues Under the Sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('said', 'captain', 'nemo'), 0.0001617115550991696),\n",
       " (('said', 'ned', 'land'), 0.00014554039958925266),\n",
       " (('replied', 'captain', 'nemo'), 0.00010511251081446025),\n",
       " (('replied', 'ned', 'land'), 8.894135530454329e-05),\n",
       " (('captain', 'nemo', 'stopped'), 5.659904428470936e-05),\n",
       " (('captain', 'nemo', 'took'), 4.851346652975088e-05),\n",
       " (('captain', 'nemo', 'went'), 4.851346652975088e-05),\n",
       " (('cried', 'ned', 'land'), 4.851346652975088e-05),\n",
       " (('let', 'us', 'go'), 4.851346652975088e-05),\n",
       " (('captain', 'nemo', 'appeared'), 4.04278887747924e-05),\n",
       " (('exclaimed', 'ned', 'land'), 4.04278887747924e-05),\n",
       " (('captain', 'nemo', 'entered'), 3.234231101983392e-05),\n",
       " (('captain', 'nemo', 'pointed'), 3.234231101983392e-05),\n",
       " (('let', 'us', 'try'), 3.234231101983392e-05),\n",
       " (('moment', 'captain', 'nemo'), 3.234231101983392e-05),\n",
       " (('saw', 'captain', 'nemo'), 3.234231101983392e-05),\n",
       " (('two', 'thousand', 'dollars'), 3.234231101983392e-05),\n",
       " (('answered', 'captain', 'nemo'), 2.425673326487544e-05),\n",
       " (('ask', 'captain', 'nemo'), 2.425673326487544e-05),\n",
       " (('captain', 'nemo', 'gave'), 2.425673326487544e-05),\n",
       " (('captain', 'nemo', 'joined'), 2.425673326487544e-05),\n",
       " (('captain', 'nemo', 'looked'), 2.425673326487544e-05),\n",
       " (('captain', 'nemo', 'rose'), 2.425673326487544e-05),\n",
       " (('captain', 'nemo', 'said'), 2.425673326487544e-05),\n",
       " (('continued', 'captain', 'nemo'), 2.425673326487544e-05),\n",
       " (('could', 'see', 'nothing'), 2.425673326487544e-05),\n",
       " (('could', 'still', 'see'), 2.425673326487544e-05),\n",
       " (('five', 'yards', 'long'), 2.425673326487544e-05),\n",
       " (('followed', 'captain', 'nemo'), 2.425673326487544e-05),\n",
       " (('heart', 'beat', 'fast'), 2.425673326487544e-05),\n",
       " (('let', 'us', 'continue'), 2.425673326487544e-05),\n",
       " (('nemo', 'went', 'towards'), 2.425673326487544e-05),\n",
       " (('see', 'captain', 'nemo'), 2.425673326487544e-05),\n",
       " (('six', 'feet', 'long'), 2.425673326487544e-05),\n",
       " (('three', 'thousand', 'years'), 2.425673326487544e-05)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20,000 Leagues Trigram Finder\n",
    "triFinder = nltk.TrigramCollocationFinder.from_words(leaguesTokens)\n",
    "#At Least 3 times\n",
    "triFinder.apply_freq_filter(min_freq=3)\n",
    "#No Punctuation\n",
    "triFinder.apply_word_filter(alphaFilter)\n",
    "#Scoring Methods For trigrams\n",
    "triScore = nltk.TrigramAssocMeasures()\n",
    "#Scored trigrams by frequency\n",
    "trigrams = triFinder.score_ngrams(triScore.raw_freq)\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarities\n",
    "\n",
    "There are definitely some similarities between Moby Dick and 20,00 Leagues Under the Sea. 44% of the top 50 most frequently occurring tokens were shared between the two texts. These shared most frequently occurring words words were: 'captain', 'one', 'said', 'could', 'sea', 'us', 'would', 'two', 'like', 'long', 'see', 'must', 'time', 'well', 'seemed', 'great', 'man', 'still', 'upon', 'last', 'first', and 'boat'. \n",
    "\n",
    "Captain, boat, and sea show the similarity of the setting between the two novels. The other shared frequently occurring words do not tell much about the texts as they are fairly generic nouns, adjectives, and verbs. Both novels also had the captain of the ship's name included in the most frequent words (Ahab, and Nemo). Both novels also had the highly scored bigram of Cape and Horn in terms of PMI. There is also very little difference in the complexity of the two novels, as unique words make up approximately 0.073 in both novels.\n",
    "\n",
    "Additionally, when looking at bigrams scored by frequency and PMI, both texts generally had characters  scored high in both scoring methods. Other than characters, simpler, more common words were generally scored high in terms of frequency. This is likely because in addition to intentional word pairings, there is a higher probability that these tokens will randomly appear next to each other accidentally. Dialogue phrases were especially abundant in the bigram list scored by frequency.\n",
    "\n",
    "Both texts also had similarities in the bigrams that were highly scored by PMI. These bigrams tended to be either people, places, or lengthier words. There also fewer dialogue phrases in both of the bigrams list, which is likely due to the higher frequency/probability of the prior when computing the PMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44% of the top 50 tokens are in both top 50\n",
      "\n",
      "Shared Tokens\n",
      "\n",
      " ['captain', 'one', 'said', 'could', 'sea', 'us', 'would', 'two', 'like', 'long', 'see', 'must', 'time', 'well', 'seemed', 'great', 'man', 'still', 'upon', 'last', 'first', 'boat']\n",
      "\n",
      "Fraction of unique words for 20,000 Leagues Under the Sea: 0.0727\n",
      "\n",
      "Fraction of unique words for Moby Dick: 0.0734\n"
     ]
    }
   ],
   "source": [
    "#Tokens that appeared in both top occurring 50\n",
    "#Top Moby Dick\n",
    "mobyDickTop = [w for w, c in mobyDict.most_common(50)]\n",
    "#20k leagues top\n",
    "leagueTop = [w for w, c in leaguesDict.most_common(50)]\n",
    "#tokens in both\n",
    "both_tokens = [w for w in leagueTop if w in mobyDickTop]\n",
    "#Percentage of the top 50 in both\n",
    "print(\"{:.0f}% of the top 50 tokens are in both top 50\".format(len(both_tokens) / 50 * 100))\n",
    "\n",
    "print(\"\\nShared Tokens\\n\\n\", both_tokens)\n",
    "\n",
    "#20,000 League Under the Sea Word choice\n",
    "print(\"\\nFraction of unique words for 20,000 Leagues Under the Sea: {:.4f}\".format(\n",
    "    len(set(leaguesTokens)) / len(leaguesTokens)))\n",
    "\n",
    "#Moby Dick Word choice\n",
    "print(\"\\nFraction of unique words for Moby Dick: {:.4f}\".format(\n",
    "    len(set(mobydickTokens)) / len(mobydickTokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences\n",
    "\n",
    "While there are some similarities, the differences between the two novels outweigh the similarities. Firstly, the American-isms are present in Moby Dick, and absent from 20,000 Leagues Under the Sea. This is seen by the the requently occurring words in Moby Dick, which include \"ye\", \"thou\", and \"n't\", while the 20,000 Leagues Under the Sea tokens are simple words that one could expect to in simplistic writings including \"land\", \"feet\", and \"large\". This difference is also exacerbated by the presence of different contractions in the frequently occurring Moby Dick bigram list (4), and the complete absence of them in the 20,000 Leagues Under the Sea. This could be because the translator wanted to transcribe a more formal translation of the book.\n",
    "\n",
    "One noticable differences between the two texts can be seen in the bigrams. The most frequently occurring bigrams in Moby Dick were related to the plot or some sort of decriptive phrase. Sperm whale was the most frequently occurring bigram becuse the fictional whale and main character in the story was a sperm whale. In fact, of the 50 most commonly occurring bigrams in Moby Dick, eight different bigrams were whale related. 20,000 Leagues Under the Sea's top 5 bigrams were related to either a person's name or a boat in the novel. The most frequently appearing bigrams in 20,000 Leagues Under the Sea were generally either names, verb phrases, measurements, or locations.\n",
    "\n",
    "The differences in the frequently appearing bigrams show that there has been a more focused effort to be descriptive of the characters and surrounding in Moby Dick, while the 20,000 Leagues Under the Sea translation was more focused on dialogue and the storytelling. This difference is especially noticable when comparing the dialogue phrases used in each of the novels. When a character is speaking in Moby Dick, they tend to be crying, or in some form anguish (cried ahab, cried stubb, cried starbuck). In 20,000 Leagues Under the Sea, verb phrasing in the dialogue is more neutral (said conseil, said captain, replied conseil).\n",
    "\n",
    "The trigrams analysis further support the idea that the 20,000 Leagues Under the Sea translation was more related to the actions and interaction of characters than Moby Dick. 25 of the 35 trigrams 20,000 Leagues were contained part of a characters name and a verb. This would suggest a more simplified story being told in 20,000 Leagues Under the Sea, primarily of dialogue and actions of characters. The trigrams present Moby Dick are largely whaling related or random general phrases. Additionally, the trigrams in 20,000 Leagues Under the sea occur more often than the trigrams in Moby Dick, as the top eight trigrams in 20,000 Leagues Under the Sea appeared more often than the top trigram in Moby Dick.\n",
    "\n",
    "These large difference in style are ones that I think could be attributed to the translation of the book. Moby dick was written in Melville's native English, in which he knows how he wants the book to sound in English. I would imagine that if 20,000 Leagues Under the Sea had been written in English, it would share some of the same anguish in the dialogue; however, this keeps the dialogue phrases simple with the verbs replied and said. It is also interesting at how many frequently occurring bigrams in 20,000 Leagues Under the Sea have to deal with numbers and measurements. The style of focusing on the story and the characters in the 20,000 Leagues translation becomes even more apparent when looking at the frequency of the bigrams. The (Captain, Nemo) bigram appears more than four times as frequent as the most frequently appearing bigram in Moby Dick (sperm, whale); additionally, the (Ned, Land) bigram appears more than twice as often as most frequently occurring Moby Dick bigram.\n",
    "\n",
    "In terms of bigrams scored by PMI, Moby Dick's bigrams tend to be either names, places or descriptions. 20,000 Leagues also has some bigrams of places, but there is also a major scientific and engineering theme. This is especially apparent with carbonic acid having the highest PMI score while appearing a minimum of five times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20,000 Leagues Only Frequently Occurring Tokens\n",
      "\n",
      " ['nautilus', 'nemo', 'ned', 'conseil', 'land', 'water', 'sir', 'feet', 'surface', 'canadian', 'day', 'without', 'replied', 'made', 'ocean', 'saw', 'air', 'went', 'light', 'miles', 'yards', 'vessel', 'waves', 'waters', 'know', 'nothing', 'large', 'board']\n",
      "\n",
      "Moby Dick Only Frequently Occurring Tokens\n",
      "\n",
      " ['whale', 'ahab', 'ship', 'old', 'ye', 'though', 'yet', 'head', 'thou', 'whales', 'way', 'stubb', \"n't\", 'queequeg', 'little', 'white', 'round', 'say', 'sperm', 'three', 'men', 'may', 'every', 'much', 'never', 'hand', 'good', 'almost']\n"
     ]
    }
   ],
   "source": [
    "#Frequently occurring tokens in only 20000 Leagues\n",
    "leagueOnlyTokens = [w for w in leagueTop if w not in mobyDickTop]\n",
    "#Frequently occurring tokens in only Moby Dick\n",
    "mobyDickOnlyTokens = [w for w in mobyDickTop if w not in leagueTop]\n",
    "\n",
    "print(\"\\n20,000 Leagues Only Frequently Occurring Tokens\\n\\n\", leagueOnlyTokens)\n",
    "print(\"\\nMoby Dick Only Frequently Occurring Tokens\\n\\n\", mobyDickOnlyTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
